{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954c7e14-20be-44ac-b427-877d02aec8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import os\n",
    "from FACS_Sampling.utils import create_adata\n",
    "\n",
    "sc.set_figure_params(figsize=(8,8), fontsize=15, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05fc093-763f-4183-a933-0afd8df7b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, using CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbdc0c54-afa9-4695-a340-835123bdf855",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus_per_node = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a2c0999-cf68-47cb-9072-6cf9fd8a0dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gpus_per_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b23458-969f-4b46-b3ab-06f0554e4228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b5dac9e-8e58-4f6b-86ae-a49511c6932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the file path from the environment variable\n",
    "file_path_env = os.getenv('MY_FACS_DATA_PATH')\n",
    "input_file1 = os.path.join(file_path_env,'sara_data',\"adata_ref_sara_2M.h5ad\")\n",
    "input_file2 = os.path.join(file_path_env,'sara_data', 'reps',\"random_adata_2_30__0.h5ad\")\n",
    "input_file3 = os.path.join(file_path_env,'sara_data', 'reps',\"fsbs_adata_2_30__0.h5ad\")\n",
    "\n",
    "adata_ref = sc.read_h5ad(input_file1)\n",
    "adata_random = sc.read_h5ad(input_file2)\n",
    "adata_fsbs =  sc.read_h5ad(input_file3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18acab75-9d9e-4c7b-93b4-b9f8f81f44bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_key = 'population'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7180c45-83d7-4847-92d3-49527b54357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_random.obs.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2dd9372-54f2-49d5-b858-febd525f4024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FACS_Sampling.methods.methods import bin_sample, sample_random\n",
    "seed = 12345\n",
    "np.random.seed(seed)\n",
    "new_seed = np.random.randint(100000)\n",
    "\n",
    "ps, _ = bin_sample(adata_random, n_bins=30, s_size=100, seed=new_seed)\n",
    "rs = sample_random(adata_random, s_size=ps.size, seed=new_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167765eb-f3ee-48b9-9aae-80c2db434a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekarimi/miniconda3/envs/facs_sampling/lib/python3.10/site-packages/anndata/_core/anndata.py:183: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/home/ekarimi/miniconda3/envs/facs_sampling/lib/python3.10/site-packages/anndata/_core/anndata.py:183: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "ad_random = adata_random[rs].copy()\n",
    "ad_fsbs = adata_random[ps].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ae0c8-5a04-489b-9855-545f7e7c1e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6b029-60e7-46f1-aefe-a200940fd570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a78db54c-b314-44cb-91e5-601ccc35cae8",
   "metadata": {},
   "source": [
    "### Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fefba781-b208-407b-8c4e-f3eba341f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class CustomLabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "    def fit(self, labels):\n",
    "        self.label_encoder.fit(labels)\n",
    "\n",
    "    def encode(self, labels):\n",
    "        # Encode a list of labels and return the encoded results as a list\n",
    "        return self.label_encoder.transform(labels).tolist()\n",
    "\n",
    "    def decode(self, encoded_labels):\n",
    "        # Decode a list of encoded results and return the actual labels as a list\n",
    "        return self.label_encoder.inverse_transform(encoded_labels).tolist()\n",
    "\n",
    "# Example usage:\n",
    "custom_encoder = CustomLabelEncoder()\n",
    "\n",
    "# Original labels\n",
    "labels = ad_fsbs.obs['population'].values\n",
    "\n",
    "# Fit the encoder with the labels\n",
    "custom_encoder.fit(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022ffcb4-ef7d-4c7e-a550-0422d048c523",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02e73d-cd2a-4c62-a865-6008447eabde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b35af6-7546-489b-afeb-f180a6235012",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsbs_labels = custom_encoder.encode(ad_fsbs.obs['population'].values)\n",
    "random_labels = custom_encoder.encode(ad_random.obs['population'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd51777-6c4e-46ef-8afa-6fcdf19de890",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fsbs, y_train_fsbs = (ad_fsbs.X, fsbs_labels)\n",
    "X_train_random, y_train_random = (ad_random.X, random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c762ad9-07ca-4e65-ac42-98dbcaba55b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab9280-f931-4a6e-8b96-b514c589a52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cc658d8-932c-474d-a512-0b087fe7c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 43\n",
    "np.random.seed(seed)\n",
    "\n",
    "rem_indices = list(set(adata_ref.obs.index) - set(adata_random.obs['index'].values))\n",
    "validation_indices = np.random.choice(rem_indices, size=50000, replace=False).tolist()\n",
    "\n",
    "valid_labels = custom_encoder.encode(adata_ref[validation_indices].obs['population'].values.copy())\n",
    "X_valid, y_valid = (adata_ref[validation_indices].X.copy(), valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ab020-042a-4d0e-8c2f-8a96d7c1e0eb",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27884149-663b-427b-a614-129163359b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(22, 10),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(10, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "# Define the Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(2, 10),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(10, 22),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "# Define the Classifier\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Linear(2, 16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the models\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "classifier = Classifier()\n",
    "\n",
    "# Define the loss functions and optimizer\n",
    "criterion_ae = nn.MSELoss()  # For the autoencoder\n",
    "criterion_cl = nn.CrossEntropyLoss()  # For the classifier\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()) + list(classifier.parameters()), lr=0.001)\n",
    "\n",
    "# Training Loop (Pseudo-code)\n",
    "for epoch in range(num_epochs):\n",
    "    for data in data_loader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Forward pass through encoder and decoder\n",
    "        encoded = encoder(inputs)\n",
    "        decoded = decoder(encoded)\n",
    "\n",
    "        # Forward pass through classifier\n",
    "        class_outputs = classifier(encoded)\n",
    "\n",
    "        # Compute loss\n",
    "        loss_ae = criterion_ae(decoded, inputs)\n",
    "        loss_cl = criterion_cl(class_outputs, labels)\n",
    "        total_loss = loss_ae + loss_cl\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Using the encoder\n",
    "# new_data = ...  # Your new data\n",
    "# encoded_representation = encoder(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6f6d1-e8b6-41cd-a73b-8bd9e349a883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf079b0a-4bb9-4a8a-890e-887ad2b5de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have two dataframes: df_train for training and df_val for validation\n",
    "# df_train = pd.read_csv('train_data.csv')\n",
    "# df_val = pd.read_csv('val_data.csv')\n",
    "\n",
    "# Example preprocessing\n",
    "scaler = StandardScaler()\n",
    "df_train_features = scaler.fit_transform(df_train.drop('label_column', axis=1))\n",
    "df_val_features = scaler.transform(df_val.drop('label_column', axis=1))\n",
    "\n",
    "df_train_labels = df_train['label_column'].values\n",
    "df_val_labels = df_val['label_column'].values\n",
    "\n",
    "# Custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(df_train_features, df_train_labels)\n",
    "val_dataset = CustomDataset(df_val_features, df_val_labels)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training Loop (Pseudo-code)\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    for inputs, labels in train_loader:\n",
    "        # Train your model\n",
    "\n",
    "    # Validation phase\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            # Validate your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0907a8-1192-4a68-8484-6f1cebdf00bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fcdbed-7a62-4137-9c70-7b14fa305570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check if CUDA (GPU support) is available\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, using CPU instead.\")\n",
    "\n",
    "# 2. Move your model to the chosen device\n",
    "model = YourModel()\n",
    "model.to(device)\n",
    "\n",
    "# 3. When loading data, send the data to the same device\n",
    "for inputs, labels in dataloader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    # Forward pass, backward pass, optimize\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640c01b-e789-4755-928c-07fe72b7df76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab61f5-9446-4e39-beec-35aa0b0f10c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05a816-cf70-45b3-979d-c1a253c652a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ee85068-73f2-4583-9c53-d43386477c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "clf_ra = lgb.LGBMClassifier(\n",
    "    num_leaves=31,  # This is just a starting point, adjust based on performance and overfitting\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=100,\n",
    "    num_class=16,  # Set this to the number of classes\n",
    "    objective='multiclass'  # Specify the multiclass objective\n",
    ")\n",
    "\n",
    "clf_fs = lgb.LGBMClassifier(\n",
    "    num_leaves=31,  # This is just a starting point, adjust based on performance and overfitting\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=100,\n",
    "    num_class=16,  # Set this to the number of classes\n",
    "    objective='multiclass'  # Specify the multiclass objective\n",
    ")\n",
    "\n",
    "# clf_ra = lgb.LGBMClassifier()\n",
    "# clf_fs = lgb.LGBMClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb09c8-6275-4dc9-84e5-ce2a6343a199",
   "metadata": {},
   "source": [
    "## Train data\n",
    "### Goal is to compare models being traind on different data to see how good the data is affecting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cfdc05-750b-4ee4-b78d-f0ef7d62c2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fdaf94c-457b-48af-833a-907a0d19f856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5610\n",
      "[LightGBM] [Info] Number of data points in the train set: 28245, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score -2.128380\n",
      "[LightGBM] [Info] Start training from score -2.990964\n",
      "[LightGBM] [Info] Start training from score -3.581715\n",
      "[LightGBM] [Info] Start training from score -1.595375\n",
      "[LightGBM] [Info] Start training from score -4.568499\n",
      "[LightGBM] [Info] Start training from score -3.469887\n",
      "[LightGBM] [Info] Start training from score -5.388859\n",
      "[LightGBM] [Info] Start training from score -4.321746\n",
      "[LightGBM] [Info] Start training from score -1.453695\n",
      "[LightGBM] [Info] Start training from score -3.495234\n",
      "[LightGBM] [Info] Start training from score -1.790168\n",
      "[LightGBM] [Info] Start training from score -2.972115\n",
      "[LightGBM] [Info] Start training from score -4.177934\n",
      "[LightGBM] [Info] Start training from score -4.337875\n",
      "[LightGBM] [Info] Start training from score -5.173498\n",
      "[LightGBM] [Info] Start training from score -3.709086\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5610\n",
      "[LightGBM] [Info] Number of data points in the train set: 28245, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score -2.321347\n",
      "[LightGBM] [Info] Start training from score -3.066320\n",
      "[LightGBM] [Info] Start training from score -3.574110\n",
      "[LightGBM] [Info] Start training from score -1.669255\n",
      "[LightGBM] [Info] Start training from score -3.940573\n",
      "[LightGBM] [Info] Start training from score -3.279821\n",
      "[LightGBM] [Info] Start training from score -4.492930\n",
      "[LightGBM] [Info] Start training from score -3.987180\n",
      "[LightGBM] [Info] Start training from score -1.610146\n",
      "[LightGBM] [Info] Start training from score -3.156930\n",
      "[LightGBM] [Info] Start training from score -2.066672\n",
      "[LightGBM] [Info] Start training from score -2.744280\n",
      "[LightGBM] [Info] Start training from score -3.064801\n",
      "[LightGBM] [Info] Start training from score -4.177934\n",
      "[LightGBM] [Info] Start training from score -4.521824\n",
      "[LightGBM] [Info] Start training from score -3.082406\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.05, num_class=16, objective=&#x27;multiclass&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.05, num_class=16, objective=&#x27;multiclass&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.05, num_class=16, objective='multiclass')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ra.fit(\n",
    "    X_train_random, y_train_random,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_metric='logloss', # You can choose the metric relevant to your problem\n",
    "    # early_stopping_rounds=10, # Stops training if one metric of one validation data doesn’t improve in last 10 rounds\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "clf_fs.fit(\n",
    "    X_train_fsbs, y_train_fsbs,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_metric='logloss', # You can choose the metric relevant to your problem\n",
    "    # early_stopping_rounds=10, # Stops training if one metric of one validation data doesn’t improve in last 10 rounds\n",
    "    # verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e13e766-d456-4439-917d-0d5d3efab708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c176cec-f9c2-49e3-9209-81f1f25b39f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clf_fs.fit(X_train_fsbs, y_train_fsbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35d4f671-8ba5-4989-a1c4-03b6e1b4624a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clf_ra.fit(X_train_random, y_train_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3319a-d1a2-44f4-a743-2fa4dcdb48c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72506fd7-29a4-467d-8b25-07abebb111d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# y_pred_fs=clf_ra.predict(X_train_random)\n",
    "# accuracy=accuracy_score(y_pred_fs, y_train_random)\n",
    "# print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_train_random, y_pred_fs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7939f6-e4a7-4465-b51d-3dc1ce722fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84ce1cf9-71ad-4af7-8ed5-407c9167df87",
   "metadata": {},
   "source": [
    "#### Acc of models on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9887b30-249a-45dc-9ef3-7f673b9c72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_fs=clf_fs.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f1c6b1d-0446-4108-a8dd-35de3526793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model accuracy score: 0.9248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# accuracy_val_fs=accuracy_score(y_pred_fs, y_valid)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_valid, y_pred_fs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6dcf2-8393-486b-a4af-b9dcafe5b1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b1a4c3-1fc8-4ceb-b890-e865e36bec07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e01e4af-d5dd-476f-95ae-902dc53af2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ra=clf_ra.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dda51da1-37ce-4b18-beca-6fb8a18d3543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model accuracy score: 0.9216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_valid, y_pred_ra)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e728f22a-2465-4266-a2b3-e808dfe649b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03efea0c-ce93-4e43-8865-b012676911cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "845284fa-3a2c-48ea-90bb-e2aa9d032218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      5870\n",
      "           1       0.93      0.91      0.92      2571\n",
      "           2       0.80      0.68      0.73      1448\n",
      "           3       0.96      0.97      0.96     10302\n",
      "           4       0.84      0.76      0.80       625\n",
      "           5       0.87      0.83      0.85      1574\n",
      "           6       0.88      0.82      0.85       236\n",
      "           7       0.86      0.76      0.80       681\n",
      "           8       0.95      0.97      0.96     11531\n",
      "           9       0.91      0.87      0.89      1462\n",
      "          10       0.90      0.95      0.92      8371\n",
      "          11       0.85      0.83      0.84      2546\n",
      "          12       0.96      0.96      0.96       669\n",
      "          13       0.92      0.88      0.90       609\n",
      "          14       0.92      0.81      0.86       290\n",
      "          15       0.92      0.93      0.93      1215\n",
      "\n",
      "    accuracy                           0.92     50000\n",
      "   macro avg       0.90      0.86      0.88     50000\n",
      "weighted avg       0.92      0.92      0.92     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_valid, y_pred_fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc482ea1-563b-4a0b-bd6b-002498d8bf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      5870\n",
      "           1       0.92      0.91      0.91      2571\n",
      "           2       0.79      0.69      0.74      1448\n",
      "           3       0.96      0.97      0.96     10302\n",
      "           4       0.83      0.69      0.75       625\n",
      "           5       0.87      0.83      0.85      1574\n",
      "           6       0.86      0.69      0.76       236\n",
      "           7       0.86      0.73      0.79       681\n",
      "           8       0.95      0.97      0.96     11531\n",
      "           9       0.89      0.87      0.88      1462\n",
      "          10       0.90      0.94      0.92      8371\n",
      "          11       0.85      0.83      0.84      2546\n",
      "          12       0.92      0.96      0.94       669\n",
      "          13       0.91      0.85      0.88       609\n",
      "          14       0.95      0.66      0.78       290\n",
      "          15       0.92      0.93      0.92      1215\n",
      "\n",
      "    accuracy                           0.92     50000\n",
      "   macro avg       0.89      0.84      0.86     50000\n",
      "weighted avg       0.92      0.92      0.92     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred_ra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8705344b-a2cd-48e2-b3be-6f2271a022ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d8312d3-4713-4157-ae8b-e92ffc140a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ra = pd.DataFrame(classification_report(y_valid, y_pred_ra, output_dict=True)).T\n",
    "df_fs = pd.DataFrame(classification_report(y_valid, y_pred_fs, output_dict=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20572585-c5c4-44c1-9c2d-67b3c6fba362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006805</td>\n",
       "      <td>-0.008177</td>\n",
       "      <td>-0.000874</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016276</td>\n",
       "      <td>-0.003112</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003605</td>\n",
       "      <td>-0.014503</td>\n",
       "      <td>-0.006830</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009633</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.042888</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.002655</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.020130</td>\n",
       "      <td>0.131356</td>\n",
       "      <td>0.084138</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.001226</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.015505</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000385</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.017660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.000538</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.037335</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.019730</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.013482</td>\n",
       "      <td>0.026273</td>\n",
       "      <td>0.020255</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.024285</td>\n",
       "      <td>0.148276</td>\n",
       "      <td>0.083871</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.008137</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.00316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>0.017938</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "0              0.006805 -0.008177 -0.000874  0.00000\n",
       "1              0.016276 -0.003112  0.006405  0.00000\n",
       "2              0.003605 -0.014503 -0.006830  0.00000\n",
       "3              0.000198  0.002427  0.001297  0.00000\n",
       "4              0.009633  0.067200  0.042888  0.00000\n",
       "5             -0.002655  0.001906 -0.000266  0.00000\n",
       "6              0.020130  0.131356  0.084138  0.00000\n",
       "7             -0.001226  0.027900  0.015505  0.00000\n",
       "8              0.000385 -0.000347  0.000027  0.00000\n",
       "9              0.017660  0.000000  0.008592  0.00000\n",
       "10             0.000784  0.004898  0.002738  0.00000\n",
       "11            -0.000538  0.003142  0.001345  0.00000\n",
       "12             0.037335  0.001495  0.019730  0.00000\n",
       "13             0.013482  0.026273  0.020255  0.00000\n",
       "14            -0.024285  0.148276  0.083871  0.00000\n",
       "15             0.008137  0.008230  0.008183  0.00000\n",
       "accuracy       0.003160  0.003160  0.003160  0.00316\n",
       "macro avg      0.006608  0.024810  0.017938  0.00000\n",
       "weighted avg   0.003326  0.003160  0.003413  0.00000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fs - df_ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bbb158-4019-427d-9aae-fb1f8b982cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
